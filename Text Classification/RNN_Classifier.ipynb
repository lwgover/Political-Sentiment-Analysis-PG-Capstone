{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from curses.ascii import isalpha, isdigit\n",
    "from plistlib import InvalidFileException\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "from Bill import Bill,CongressPerson\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bills(folder:str):\n",
    "    bill_locations = os.listdir(folder)\n",
    "    bill_locations = list(map(lambda loc:folder + '/' + loc, bill_locations))\n",
    "    bills = []\n",
    "    for bill_file in bill_locations:\n",
    "        if bill_file[-3:] == 'txt':\n",
    "            try:\n",
    "                bills.append(Bill(bill_file))\n",
    "            except InvalidFileException as e:\n",
    "                continue\n",
    "    return bills\n",
    "\n",
    "def to_word_vector(translator:dict, bill:Bill):\n",
    "    \"\"\" Turns paper to a vector of word counts using the indicies from translator \"\"\"\n",
    "    vector = np.array([0] * len(translator), dtype = 'uint8')\n",
    "    words = \"\"\n",
    "    if type(bill) == str:\n",
    "        words = get_words(bill)\n",
    "    else:\n",
    "        words = get_words_bill(bill)\n",
    "    for word in words:\n",
    "        if word in translator:\n",
    "            index = translator[word]\n",
    "            vector[index] += 1\n",
    "    new_vector = []\n",
    "    for cell in vector:\n",
    "        if type(bill) == str:\n",
    "            new_vector += [100000 * (cell / len(bill))]\n",
    "        else:\n",
    "            new_vector += [100000 * (cell / len(bill.text))]\n",
    "    return np.array(new_vector, dtype = 'uint8') \n",
    "\n",
    "def make_translator(bills:list):\n",
    "    \"\"\" makes a dictionary with word as input, index in word count vector as output \"\"\"\n",
    "    words = set()\n",
    "    for bill in bills:\n",
    "        for word in get_words_bill(bill):\n",
    "            if word not in words:\n",
    "                words.add(word)\n",
    "    counter = 0\n",
    "    translator = dict()\n",
    "    for word in words:\n",
    "        translator[word] = counter\n",
    "        counter += 1\n",
    "\n",
    "    return translator\n",
    "\n",
    "def get_words_bill(bill:Bill):\n",
    "    words = []\n",
    "    current_word = ''\n",
    "    for character in bill.text.lower():\n",
    "        if isdigit(character) or isalpha(character):\n",
    "            current_word += character\n",
    "        else:\n",
    "            if len(current_word) > 0:\n",
    "                words.append(current_word)\n",
    "                current_word = ''\n",
    "\n",
    "    return words\n",
    "\n",
    "def get_words(bill:str):\n",
    "    words = []\n",
    "    current_word = ''\n",
    "    for character in bill.lower():\n",
    "        if isdigit(character) or isalpha(character):\n",
    "            current_word += character\n",
    "        else:\n",
    "            if len(current_word) > 0:\n",
    "                words.append(current_word)\n",
    "                current_word = ''\n",
    "\n",
    "    return words\n",
    "\n",
    "\n",
    "def make_labels(bills):\n",
    "    parties = set()\n",
    "    for bill in bills:\n",
    "        if bill.party not in parties:\n",
    "            parties.add(bill.party)\n",
    "    party_list = list(parties)\n",
    "    labels = []\n",
    "    for bill in bills:\n",
    "        label = [0] * len(party_list)\n",
    "        label[party_list.index(bill.party)] = 1\n",
    "        label = np.array(label, dtype = 'uint8')\n",
    "        labels.append(label)\n",
    "    return labels,party_list\n",
    "\n",
    "def max_index(list_of_stuff:list) -> int:\n",
    "    max_num = -1\n",
    "    max_index = 0\n",
    "    for i in range(len(list_of_stuff)):\n",
    "        if list_of_stuff[i] > max_num:\n",
    "            max_index = i\n",
    "            max_num = list_of_stuff[i]\n",
    "    return max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GloVe_file = '/Users/lucasgover/Downloads/glove.6B/glove.6B.50d.txt'\n",
    "emmbed_dict = {}\n",
    "with open(GloVe_file,'r') as f:\n",
    "  for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    vector = np.asarray(values[1:],'float32')\n",
    "    emmbed_dict[word]=vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Bills Here\n",
    "BillsLocation = '/Users/lucasgover/Desktop/AI431_Projects/AIFinal/Bills_2021-2022'\n",
    "bills = make_bills(BillsLocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(bill:str):\n",
    "    words = []\n",
    "    current_word = ''\n",
    "    for character in bill.lower():\n",
    "        if isdigit(character) or isalpha(character):\n",
    "            current_word += character\n",
    "        else:\n",
    "            if len(current_word) > 0:\n",
    "                words.append(current_word)\n",
    "                current_word = ''\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import ideologyTags\n",
    "SenatorsFile = '/Users/lucasgover/Desktop/Political-Sentiment-Analysis-PG-Capstone/Ideological_Tags/govtrack-stats-2020-house-ideology.csv'\n",
    "HouseFile = '/Users/lucasgover/Desktop/Political-Sentiment-Analysis-PG-Capstone/Ideological_Tags/govtrack-stats-2020-house-ideology.csv'\n",
    "\n",
    "StateAndNameToIdeology = dict()\n",
    "\n",
    "with open (SenatorsFile, \"r\") as SenateIdeologyCSV:\n",
    "    data = SenateIdeologyCSV.read()\n",
    "    senators = data.split('\\n')[1:]\n",
    "    for senator in senators:\n",
    "        splitSenator = senator.split(',')\n",
    "        StateAndNameToIdeology[splitSenator[-3] + \" \" + splitSenator[-1][2:-1]] = float(splitSenator[3])\n",
    "       \n",
    "with open (HouseFile, \"r\") as HouseIdeologyCSV:\n",
    "    data = HouseIdeologyCSV.read()\n",
    "    reps = data.split('\\n')[1:]\n",
    "    for rep in reps:\n",
    "        splitRep = rep.split(',')\n",
    "        StateAndNameToIdeology[splitRep[-3] + \" \" + splitRep[-1][2:-1]] = float(splitRep[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bill_to_ideology(bill:Bill, ideologiesDict:dict):\n",
    "    totalIdeology = 0\n",
    "    numSponsors = 1\n",
    "    currentCongressPerson = bill.sponsor\n",
    "    if (currentCongressPerson.state + \" \" + currentCongressPerson.full_name.split(',')[0]) in ideologiesDict:\n",
    "        totalIdeology = ideologiesDict[(currentCongressPerson.state + \" \" + currentCongressPerson.full_name.split(',')[0])]\n",
    "        numSponsors = 1\n",
    "    for sponsor in bill.cosponsors:\n",
    "        currentCongressPerson = sponsor\n",
    "        if (currentCongressPerson.state + \" \" + currentCongressPerson.full_name.split(',')[0]) in ideologiesDict:\n",
    "            totalIdeology += ideologiesDict[(currentCongressPerson.state + \" \" + currentCongressPerson.full_name.split(',')[0])]\n",
    "            numSponsors += 1 \n",
    "    return totalIdeology / numSponsors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bills_to_dataset(bills_list:list):\n",
    "    CHUNK_SIZE = 100\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for bill in bills_list:\n",
    "        words = get_words(bill.title + bill.text)\n",
    "        num_chunks = len(words) // CHUNK_SIZE\n",
    "        if bill.sponsor == None:\n",
    "            continue\n",
    "        bill_ideology = bill_to_ideology(bill,StateAndNameToIdeology)\n",
    "        for i in range(num_chunks):\n",
    "            texts += [dataset_to_embedding_dataset(words[:CHUNK_SIZE])]\n",
    "            words = words[CHUNK_SIZE:]\n",
    "            labels += [bill_ideology]\n",
    "        print(len(texts))\n",
    "        print(len(labels))\n",
    "    return texts,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emmbed_dims = len(emmbed_dict[emmbed_dict.keys[0]])\n",
    "\n",
    "\n",
    "embedding_matrix = np.zeros((len(emmbed_dict), emmbed_dims))\n",
    "for word, i in emmbed_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
